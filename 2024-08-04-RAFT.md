## [논문 리뷰] RAFT: Adapting Language Model to Domain Specific RAG

버클리의 연구진이 작성한 [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/pdf/2403.10131v2) 논문을 퀵하게 요약한 내용입니다.

## 요약

- 특정 분야의 RAG 태스크에서 뛰어난 성능을 보여주는 Retrieval Augemented Fine Tuning(RAFT) 구조를 제안
- (question, golden doc., distractor doc., C-o-T style answer) 형태로 이루어진 데이터셋에 대해 파인튜닝한 이후, inference 시에는 (question, top-k documents)를 사용
- 일부 데이터에 대해 golden document를 포함시키지 않도록 데이터셋을 구성하면 더 성능이 좋아짐

## 배경

* Main Question: How do we adapt pre-trained LLMs for RAG in specialized domains?
  * 일반적인 RAG : 특정 도메인의 정보를 학습할 기회가 없음
  * 지도 파인튜닝 : 도메인의 정보를 학습할 수 있으나 인퍼런스 시에 주어진 문맥 정보를 활용하지 못할 때가 있음
* RAFT는 question Q, (relevant and distractor) documents (D\*), chain-of-thought 스타일의 답변 (A\*) 으로 구성된 데이터를 학습하여 좋은 성능을 보임<br>
  ![image1](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image1.png)

## RAFT

* 전통적인 지도 파인튜닝(SFT)는 다음 구조로 이루어짐
  {Train: Q -> A}, {0-shot Inference: Q -> A}, {RAG Inference: Q + D -> A}
* RAFT의 데이터셋은 다음 요소들로 이루어짐 : 질문 Q, 문서집합 (D_k), 문서 중 하나 D\*로부터 도출한 Chain-of-thought 스타일의 답변 A\*
  * (D_k)는 golden documents (D\*)와 k개의 distractor documents (D_i) 들로 구성
  * GPT4를 이용하여 정답을 Chain-of-thought 스타일로 재생성<br>
    ![image2](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image2.png)
* 각 데이터 별로 전체의 P%는 golden/distractor documents를 모두 포함 / (1-P)%는 golden documents 없이 distractor documents만 포함하도록도록 구성
* 테스트 시에는 질문 Q와 RAG를 통해 산출한 top-k documents로 구성하여 수행

## 결과

* 여러 도메인의 데이터셋과 모델을 이용하여 정화가도를 평가한 결과, RAFT가 전체적으로 뛰어난 성능을 보임<br>
  ![image3](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image3.png)
* 단순히 질문-답변 형식으로 파인튜닝하는 경우, 오버피팅의 우려가 있기에 Chain-of-Thought 방식으로 생성한 답변을 사용하였으며, 이로 인해 성능 차이 크게 발생<br>
  ![image4](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image4.png)
* Context documents에 golden documents를 포함하지 않은 경우가 적절히 포함되어 있을 때 성능이 더 좋아지는 경향<br>
  ![image5](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image5.png)

## RAFT를 이용한 Top-K RAG 일반화

* 일반적으로 RAG 모델에서 후보 documents는 top-k 방식을 사용하여 추출하는데, 이때 이 k와 Distractor documents의 수의 관계에 대해 탐색함

* 모델 학습 과정에서 golden document 1개 + distractor documents 0~3개로 구성된 데이터셋을 이용하고, 테스트 시에는 Top-k(k in [0,2,4,6,8]) 방식을 사용한 결과, distractor documents의 수는 태스크마다 다르지만 전체적으로 0개는 별로였음<br>
  ![image6](https://github.com/lih0905/coffee-augmented-rag/blob/main/images/240804/image6.png)

* 또한 테스트 시에는 다양한 갯수의 documents를 만나게 되는데, distractor documents 를 포함한 경우에 이런 다양한 갯수에 더 강건한 모습을 보임

  